{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import src as functions\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "import re\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, sent_tokenize\n",
    "from sklearn.model_selection import train_test_split, cross_validate , GridSearchCV, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline , Pipeline\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords as sw\n",
    "from sklearn.linear_model import LogisticRegression , SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import warnings\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline as imbpipe\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "warnings.filterwarnings (\"ignore\")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import plot_confusion_matrix , fbeta_score, make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df,review_col):\n",
    "    '''Returns a DataFrame transformed and ready to be tested. Returns the df with \n",
    "    Tokens, Number of words, Char Review Count, Sentences and Sentence Count'''\n",
    "    df_engineered = df.copy()\n",
    "    # Make a column to split words up, puncuation is included\n",
    "    df_engineered['Tokens'] = df[review_col].str.split(' ')\n",
    "    # Find the number of words in each review\n",
    "    df_engineered['Number of Words'] = df_engineered['Tokens'].map(lambda x: len(x))\n",
    "    # Find number of characters used in Reviews\n",
    "    df_engineered['Character Review Length'] = df_engineered[review_col].map(lambda x: len(x))\n",
    "    # Find Number of Sentences in Each Review\n",
    "    df_engineered['Sentences'] = df_engineered[review_col].map(lambda x:sent_tokenize(x))\n",
    "    df_engineered['Sentence Count'] = df_engineered['Sentences'].map(lambda x : len(x))\n",
    "    df_engineered['Avg Words Per Sentence'] = df_engineered['Number of Words'] / df_engineered['Sentence Count']\n",
    "    return df_engineered\n",
    "\n",
    "def test_df(df,review_col):\n",
    "    X = df.copy()\n",
    "    X = df[[review_col,'Number of Words','Character Review Length','Sentence Count','Avg Words Per Sentence']]\n",
    "    # Remove all numbers\n",
    "    X[review_col] = X[review_col].str.replace('\\d+', '')\n",
    "    # Make a tokenize column\n",
    "    X['token'] = X[review_col].map(lambda x: word_tokenize(x))\n",
    "    # Stem words in the tokenized column then create a column where they are joined\n",
    "    X['stem'] = X['token'].apply(lambda x: [SnowballStemmer('english').stem(y) for y in x])\n",
    "    X['sentence'] = X['stem'].apply(lambda x : ' '.join(x))\n",
    "    # Add all of our extra features in\n",
    "    X = X[['sentence','Number of Words','Character Review Length','Sentence Count','Avg Words Per Sentence']]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our Test DF into our notebook\n",
    "df  = pd.read_csv('data/Labelled Yelp Dataset Edited.csv')\n",
    "\n",
    "df_test = transform(df,'Review')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Multinomial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabel our targets to a traditional 0 1 label\n",
    "binary_dict = {1:0,-1:1}\n",
    "df_test['Label'] = df_test['Label'].map(binary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This takes out the puncuation and makes everything lower cased. Numbers are still included in this model.\n",
    "df_test['Test Column'] = df_test['Review'].str.replace(r'[^\\w\\s]', '')\n",
    "df_test['Test Column'] = df_test['Test Column'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test['Test Column']\n",
    "y = df_test['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pipeline and cross validate\n",
    "first_model = make_pipeline(TfidfVectorizer(stop_words=sw.words('english')), MultinomialNB())\n",
    "first_model_results = cross_validate(first_model, X_train, y_train,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.9005521894667872\n",
      "Mean Test Score: 0.9003196246246615\n"
     ]
    }
   ],
   "source": [
    "functions.mean_scores(first_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.0010756543564001434\n",
      "Precision Score: 1.0\n",
      "Accuracy Score:0.9003196259898865\n",
      "F1 Score: 0.002148997134670487\n",
      "Confusion Matrix: \n",
      "[[75481     0]\n",
      " [ 8358     9]]\n"
     ]
    }
   ],
   "source": [
    "y_preds = cross_val_predict(first_model, X_train, y_train)\n",
    "functions.metrics(y_train,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the simple model has a hard time catching the fake reviews. This has no stemming or over/under sampling techniques. Future iterations will experiment with these along with other features that have been engineered. Also the matrics I am thinking about are either F1 or Recall. This is because I intend this system to flag reviews for a person to look at. This would mean it is okay to have more false positives because the reviews will be peer reviewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model = make_pipeline(TfidfVectorizer(stop_words=sw.words('english')),LogisticRegression())\n",
    "second_results = cross_validate(second_model,X_train,y_train,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.9009815384159419\n",
      "Mean Test Score: 0.8996159757976898\n"
     ]
    }
   ],
   "source": [
    "functions.mean_scores(second_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.007768614796223258\n",
      "Precision Score: 0.3611111111111111\n",
      "Accuracy Score:0.89961597175842\n",
      "F1 Score: 0.01521001521001521\n",
      "Confusion Matrix: \n",
      "[[75366   115]\n",
      " [ 8302    65]]\n"
     ]
    }
   ],
   "source": [
    "y_preds_LR = cross_val_predict(second_model, X_train, y_train)\n",
    "functions.metrics(y_train,y_preds_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is an improvement, this is picking up more on the fake reviews than the NB model did. This is a good step in the right direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost TFIDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_model = make_pipeline(TfidfVectorizer(stop_words=sw.words('english')),XGBClassifier())\n",
    "xg_results = cross_validate(xg_model,X_train,y_train,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.9062052780226235\n",
      "Mean Test Score: 0.8997113878211751\n"
     ]
    }
   ],
   "source": [
    "functions.mean_scores(xg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.006214891836978606\n",
      "Precision Score: 0.3561643835616438\n",
      "Accuracy Score:0.8997113825016697\n",
      "F1 Score: 0.012216609890755315\n",
      "Confusion Matrix: \n",
      "[[75387    94]\n",
      " [ 8315    52]]\n"
     ]
    }
   ],
   "source": [
    "xg_preds = cross_val_predict(xg_model,X_train,y_train)\n",
    "functions.metrics(y_train,xg_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the Logistic model, less positives but less FP also. Right now the LR model is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.7226827273824232\n",
      "Mean Test Score: 0.7001956800984354\n"
     ]
    }
   ],
   "source": [
    "imb_log_model = imbpipe(steps=[\n",
    "                         ('tfid',TfidfVectorizer(stop_words=sw.words('english'))),\n",
    "                         ('over',RandomOverSampler(sampling_strategy='minority')),\n",
    "                         ('LR',LogisticRegression(C=.1))])\n",
    "\n",
    "imb_log_results = cross_validate(imb_log_model,X_train,y_train,return_train_score=True)\n",
    "functions.mean_scores(imb_log_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.6134815346002152\n",
      "Precision Score: 0.18946552487819282\n",
      "Accuracy Score:0.6995396431638202\n",
      "F1 Score: 0.2895174708818636\n",
      "Confusion Matrix: \n",
      "[[53522 21959]\n",
      " [ 3234  5133]]\n"
     ]
    }
   ],
   "source": [
    "imb_log_preds = cross_val_predict(imb_log_model,X_train,y_train)\n",
    "functions.metrics(y_train,imb_log_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has by far been the best model yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.8150075057186668\n",
      "Mean Test Score: 0.7532559785955378\n"
     ]
    }
   ],
   "source": [
    "imb_bayes_model = imbpipe(steps=[\n",
    "                         ('tfid',TfidfVectorizer(stop_words=sw.words('english'))),\n",
    "                         ('over',RandomOverSampler(sampling_strategy='minority')),\n",
    "                         ('bae',MultinomialNB())])\n",
    "\n",
    "imb_bayes_results = cross_validate(imb_bayes_model,X_train,y_train,return_train_score=True)\n",
    "functions.mean_scores(imb_bayes_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.4896617664634875\n",
      "Precision Score: 0.19834430673896206\n",
      "Accuracy Score:0.7515862036065261\n",
      "F1 Score: 0.2823278089790856\n",
      "Confusion Matrix: \n",
      "[[58922 16559]\n",
      " [ 4270  4097]]\n"
     ]
    }
   ],
   "source": [
    "imb_bayes_preds = cross_val_predict(imb_bayes_model,X_train,y_train)\n",
    "functions.metrics(y_train,imb_bayes_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the same as the LR model, a little bit better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.75429944063062\n",
      "Mean Test Score: 0.6914297995637733\n"
     ]
    }
   ],
   "source": [
    "imb_boost_model = imbpipe(steps=[\n",
    "                         ('tfid',TfidfVectorizer(stop_words=sw.words('english'))),\n",
    "                         ('over',RandomOverSampler(sampling_strategy='minority')),\n",
    "                         ('boost',XGBClassifier())])\n",
    "\n",
    "imb_boost_results = cross_validate(imb_boost_model,X_train,y_train,return_train_score=True)\n",
    "functions.mean_scores(imb_boost_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.5628062626986973\n",
      "Precision Score: 0.17629441054247313\n",
      "Accuracy Score:0.6939700410266196\n",
      "F1 Score: 0.26848737100176745\n",
      "Confusion Matrix: \n",
      "[[53479 22002]\n",
      " [ 3658  4709]]\n"
     ]
    }
   ],
   "source": [
    "imb_boost_preds = cross_val_predict(imb_boost_model,X_train,y_train)\n",
    "functions.metrics(y_train,imb_boost_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has the best detection of fake reviews while not predicting everything as fake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.6697208128202929\n",
      "Mean Test Score: 0.6484472693653809\n"
     ]
    }
   ],
   "source": [
    "under_log_model = imbpipe(steps=[\n",
    "                         ('tfid',TfidfVectorizer(stop_words=sw.words('english'))),\n",
    "                         ('under',RandomUnderSampler(sampling_strategy='majority')),\n",
    "                         ('LR',LogisticRegression())])\n",
    "\n",
    "under_log_results = cross_validate(under_log_model,X_train,y_train,return_train_score=True)\n",
    "functions.mean_scores(under_log_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.6609298434325326\n",
      "Precision Score: 0.17141971481711096\n",
      "Accuracy Score:0.6473738192920523\n",
      "F1 Score: 0.27223275161838184\n",
      "Confusion Matrix: \n",
      "[[48751 26730]\n",
      " [ 2837  5530]]\n"
     ]
    }
   ],
   "source": [
    "under_log_preds = cross_val_predict(under_log_model,X_train,y_train)\n",
    "functions.metrics(y_train,under_log_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.849274869551224\n",
      "Mean Test Score: 0.8240507655090765\n"
     ]
    }
   ],
   "source": [
    "under_bayes_model = imbpipe(steps=[\n",
    "                         ('tfid',TfidfVectorizer(stop_words=sw.words('english'))),\n",
    "                         ('under',RandomUnderSampler(sampling_strategy='majority')),\n",
    "                         ('bae',MultinomialNB())])\n",
    "\n",
    "under_bayes_results = cross_validate(under_bayes_model,X_train,y_train,return_train_score=True)\n",
    "functions.mean_scores(under_bayes_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.33034540456555517\n",
      "Precision Score: 0.23025658113962014\n",
      "Accuracy Score:0.8229772922431066\n",
      "F1 Score: 0.27136615777330525\n",
      "Confusion Matrix: \n",
      "[[66241  9240]\n",
      " [ 5603  2764]]\n"
     ]
    }
   ],
   "source": [
    "under_bayes_preds = cross_val_predict(under_bayes_model,X_train,y_train)\n",
    "functions.metrics(y_train,under_bayes_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.6473738253538852\n",
      "Mean Test Score: 0.6010281337702785\n"
     ]
    }
   ],
   "source": [
    "under_boost_model = imbpipe(steps=[\n",
    "                         ('tfid',TfidfVectorizer(stop_words=sw.words('english'))),\n",
    "                         ('under',RandomUnderSampler(sampling_strategy='majority')),\n",
    "                         ('boost',XGBClassifier())])\n",
    "\n",
    "under_boost_results = cross_validate(under_boost_model,X_train,y_train,return_train_score=True)\n",
    "functions.mean_scores(under_boost_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.6800525875463129\n",
      "Precision Score: 0.15658539270185481\n",
      "Accuracy Score:0.6025546226505104\n",
      "F1 Score: 0.2545576557432055\n",
      "Confusion Matrix: \n",
      "[[44833 30648]\n",
      " [ 2677  5690]]\n"
     ]
    }
   ],
   "source": [
    "under_boost_preds = cross_val_predict(under_boost_model,X_train,y_train)\n",
    "functions.metrics(y_train,under_boost_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost model gives the highest recall score, but predicts a significant amount more of reviews being fake when they are real. The LR model comes close in recall, falling 1.5% behind the XGBoost while predicing less false positives. Hyperparameter tuning will be done for both to see which gives the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'LR__C':[.1,1,20,50],\n",
    "         'LR__solver':['lbfgs', 'liblinear', 'sag'],\n",
    "         'LR__class_weight':[None,'balanced',.25]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gs = GridSearchCV(under_log_model,params,return_train_score=True,scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfid',\n",
       "                                        TfidfVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('under',\n",
       "                                        RandomUnderSampler(sampling_strategy='majority')),\n",
       "                                       ('LR', LogisticRegression())]),\n",
       "             param_grid={'LR__C': [0.1, 1, 20, 50],\n",
       "                         'LR__class_weight': [None, 'balanced', 0.25],\n",
       "                         'LR__solver': ['lbfgs', 'liblinear', 'sag']},\n",
       "             return_train_score=True, scoring='recall')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR__C': 1, 'LR__class_weight': None, 'LR__solver': 'liblinear'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gs_ypreds = cross_val_predict(lr_gs.best_estimator_, X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.65853950041831\n",
      "Precision Score: 0.17185989208072114\n",
      "Accuracy Score:0.6492701078141399\n",
      "F1 Score: 0.2725833580686653\n",
      "Confusion Matrix: \n",
      "[[48930 26551]\n",
      " [ 2857  5510]]\n"
     ]
    }
   ],
   "source": [
    "functions.metrics(y_train,lr_gs_ypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_params = {'boost__n_estimators':[50,75,100],\n",
    "            'boost__max_depth':[1,3,4,5],\n",
    "            'boost__booster':['gbtree','dart'],\n",
    "            'boost__eta':[.1,.3,.5,.7]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfid',\n",
       "                                        TfidfVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('under',\n",
       "                                        RandomUnderSampler(sampling_strateg...\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      random_state=None,\n",
       "                                                      reg_alpha=None,\n",
       "                                                      reg_lambda=None,\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=None,\n",
       "                                                      tree_method=None,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             param_grid={'boost__booster': ['gbtree', 'dart'],\n",
       "                         'boost__eta': [0.1, 0.3, 0.5, 0.7],\n",
       "                         'boost__max_depth': [1, 3, 4, 5],\n",
       "                         'boost__n_estimators': [50, 75, 100]},\n",
       "             return_train_score=True, scoring='recall')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_gs = GridSearchCV(under_boost_model,xg_params,return_train_score=True,scoring='recall')\n",
    "boost_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.7417234373132544\n",
      "Precision Score: 0.14948093552038924\n",
      "Accuracy Score:0.5530960786184524\n",
      "F1 Score: 0.2488172560339989\n",
      "Confusion Matrix: \n",
      "[[40170 35311]\n",
      " [ 2161  6206]]\n"
     ]
    }
   ],
   "source": [
    "boost_gs_ypreds = cross_val_predict(boost_gs.best_estimator_, X_train,y_train)\n",
    "functions.metrics(y_train,boost_gs_ypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boost__booster': 'gbtree',\n",
       " 'boost__eta': 0.3,\n",
       " 'boost__max_depth': 1,\n",
       " 'boost__n_estimators': 50}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.7417234373132544\n",
      "Precision Score: 0.14948093552038924\n",
      "Accuracy Score:0.5530960786184524\n",
      "F1 Score: 0.2488172560339989\n",
      "Confusion Matrix: \n",
      "[[40170 35311]\n",
      " [ 2161  6206]]\n"
     ]
    }
   ],
   "source": [
    "functions.metrics(y_train,boost_gs_ypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.65853950041831\n",
      "Precision Score: 0.17185989208072114\n",
      "Accuracy Score:0.6492701078141399\n",
      "F1 Score: 0.2725833580686653\n",
      "Confusion Matrix: \n",
      "[[48930 26551]\n",
      " [ 2857  5510]]\n"
     ]
    }
   ],
   "source": [
    "functions.metrics(y_train,lr_gs_ypreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning - KMeans and TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = make_pipeline(TfidfVectorizer(stop_words=sw.words('english')),KMeans(n_clusters=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = cross_val_predict(knn,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.4496235209752599\n",
      "Precision Score: 0.09321340964840556\n",
      "Accuracy Score:0.5086108195782845\n",
      "F1 Score: 0.15441448097524937\n",
      "Confusion Matrix: \n",
      "[[38884 36597]\n",
      " [ 4605  3762]]\n"
     ]
    }
   ],
   "source": [
    "functions.metrics(y_train,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are models that do a better job of predicting fake than this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model with Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test[['Test Column','Number of Words','Character Review Length','Sentence Count','Avg Words Per Sentence']]\n",
    "y = df_test['Label']\n",
    "# Remove all numbers\n",
    "X['Test Column'] = X['Test Column'].str.replace('\\d+', '')\n",
    "# Make a tokenize column\n",
    "X['token'] = X['Test Column'].map(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stem words in the tokenized column then create a column where they are joined\n",
    "X['stem'] = X['token'].apply(lambda x: [SnowballStemmer('english').stem(y) for y in x])\n",
    "X['sentence'] = X['stem'].apply(lambda x : ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all of our extra features in\n",
    "X = X[['sentence','Number of Words','Character Review Length','Sentence Count','Avg Words Per Sentence']]\n",
    "#Perform train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(fbeta_score, beta=10)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.7218239373655418\n",
      "Mean Test Score: 0.704911015560226\n"
     ]
    }
   ],
   "source": [
    "# Tell TFIDF which column to vectorize\n",
    "column_transformer = ColumnTransformer(\n",
    "    [('tfidf1', TfidfVectorizer(stop_words=sw.words('english')), 'sentence')], \n",
    "    remainder='passthrough')\n",
    "\n",
    "# fit the model\n",
    "under_log_eng_model = imbpipe(steps=[('tfidf1', column_transformer),\n",
    "                                     ('under',RandomUnderSampler('majority',random_state=42)),\n",
    "                                     ('LR',LogisticRegression(C=.1,class_weight='balanced',solver='lbfgs',random_state=42))])\n",
    "# Evaluate results     \n",
    "under_log_eng_results = cross_validate(under_log_eng_model,X_train,y_train,return_train_score=True,scoring='recall')\n",
    "functions.mean_scores(under_log_eng_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.7049121548942273\n",
      "Precision Score: 0.16470719651484264\n",
      "Accuracy Score:0.61382501669688\n",
      "F1 Score: 0.26702281781963055\n",
      "Confusion Matrix: \n",
      "[[45570 29911]\n",
      " [ 2469  5898]]\n"
     ]
    }
   ],
   "source": [
    "# Metrics with confusion matrix\n",
    "under_log_stem_preds = cross_val_predict(under_log_eng_model,X_train,y_train)\n",
    "functions.metrics(y_train,under_log_stem_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.7165054607351455\n",
      "Mean Test Score: 0.7039530072462992\n"
     ]
    }
   ],
   "source": [
    "# Tell TFIDF which column to vectorize\n",
    "column_transformer = ColumnTransformer(\n",
    "    [('tfidf1', TfidfVectorizer(stop_words=sw.words('english')), 'sentence')], \n",
    "    remainder='passthrough')\n",
    "\n",
    "# fit the model\n",
    "under_boost_eng_model = imbpipe(steps=[('tfidf1', column_transformer),\n",
    "                                     ('under',RandomUnderSampler('majority',random_state=42)),\n",
    "                                     ('boost',XGBClassifier(booster='dart',eta='.3',max_depth=1,n_estimators=75,random_state=42))])\n",
    "# Evaluate results     \n",
    "under_boost_eng_results = cross_validate(under_boost_eng_model,X_train,y_train,return_train_score=True,scoring='recall')\n",
    "functions.mean_scores(under_boost_eng_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.7039560176885383\n",
      "Precision Score: 0.1572721689674508\n",
      "Accuracy Score:0.5940511401583818\n",
      "F1 Score: 0.2571041948579161\n",
      "Confusion Matrix: \n",
      "[[43920 31561]\n",
      " [ 2477  5890]]\n"
     ]
    }
   ],
   "source": [
    "# Metrics with confusion matrix\n",
    "under_boost_stem_preds = cross_val_predict(under_boost_eng_model,X_train,y_train)\n",
    "functions.metrics(y_train,under_boost_stem_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_params = {'boost__n_estimators':[50,75,100],\n",
    "            'boost__max_depth':[1,3,4,5],\n",
    "            'boost__booster':['gbtree','dart'],\n",
    "            'boost__eta':[.1,.3,.5,.7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidf1',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('tfidf1',\n",
       "                                                                         TfidfVectorizer(stop_words=['i',\n",
       "                                                                                                     'me',\n",
       "                                                                                                     'my',\n",
       "                                                                                                     'myself',\n",
       "                                                                                                     'we',\n",
       "                                                                                                     'our',\n",
       "                                                                                                     'ours',\n",
       "                                                                                                     'ourselves',\n",
       "                                                                                                     'you',\n",
       "                                                                                                     \"you're\",\n",
       "                                                                                                     \"you've\",\n",
       "                                                                                                     \"you'll\",\n",
       "                                                                                                     \"you'd\",\n",
       "                                                                                                     'your',\n",
       "                                                                                                     'yours',\n",
       "                                                                                                     'yourself',\n",
       "                                                                                                     'yourselves',\n",
       "                                                                                                     'he',\n",
       "                                                                                                     'him',\n",
       "                                                                                                     'his',\n",
       "                                                                                                     'himself',\n",
       "                                                                                                     'she',\n",
       "                                                                                                     \"she's\",\n",
       "                                                                                                     'her',\n",
       "                                                                                                     'hers',\n",
       "                                                                                                     'herself',\n",
       "                                                                                                     'it',\n",
       "                                                                                                     \"it's...\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      random_state=42,\n",
       "                                                      reg_alpha=None,\n",
       "                                                      reg_lambda=None,\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=None,\n",
       "                                                      tree_method=None,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             param_grid={'boost__booster': ['gbtree', 'dart'],\n",
       "                         'boost__eta': [0.1, 0.3, 0.5, 0.7],\n",
       "                         'boost__max_depth': [1, 3, 4, 5],\n",
       "                         'boost__n_estimators': [50, 75, 100]},\n",
       "             return_train_score=True, scoring='recall')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune parameters for XGBoost\n",
    "boost_gs = GridSearchCV(under_boost_eng_model,xg_params,return_train_score=True,scoring='recall')\n",
    "boost_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.707422015059161\n",
      "Precision Score: 0.15962783171521036\n",
      "Accuracy Score:0.5991675412651465\n",
      "F1 Score: 0.26047923955376595\n",
      "Confusion Matrix: \n",
      "[[44320 31161]\n",
      " [ 2448  5919]]\n"
     ]
    }
   ],
   "source": [
    "boost_gs_ypreds = cross_val_predict(boost_gs.best_estimator_, X_train,y_train)\n",
    "functions.metrics(y_train,boost_gs_ypreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running a gridsearch, the XGBoost model did not show much improvement. I will move forward with the LR model as it will perform better with some hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR as chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for LR model\n",
    "params = {'LR__C':[.05,.01,.1,1,5],\n",
    "         'LR__solver':['lbfgs', 'liblinear', 'sag','saga'],\n",
    "         'LR__class_weight':[None,'balanced',.25,.5,.75]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidf1',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('tfidf1',\n",
       "                                                                         TfidfVectorizer(stop_words=['i',\n",
       "                                                                                                     'me',\n",
       "                                                                                                     'my',\n",
       "                                                                                                     'myself',\n",
       "                                                                                                     'we',\n",
       "                                                                                                     'our',\n",
       "                                                                                                     'ours',\n",
       "                                                                                                     'ourselves',\n",
       "                                                                                                     'you',\n",
       "                                                                                                     \"you're\",\n",
       "                                                                                                     \"you've\",\n",
       "                                                                                                     \"you'll\",\n",
       "                                                                                                     \"you'd\",\n",
       "                                                                                                     'your',\n",
       "                                                                                                     'yours',\n",
       "                                                                                                     'yourself',\n",
       "                                                                                                     'yourselves',\n",
       "                                                                                                     'he',\n",
       "                                                                                                     'him',\n",
       "                                                                                                     'his',\n",
       "                                                                                                     'himself',\n",
       "                                                                                                     'she',\n",
       "                                                                                                     \"she's\",\n",
       "                                                                                                     'her',\n",
       "                                                                                                     'hers',\n",
       "                                                                                                     'herself',\n",
       "                                                                                                     'it',\n",
       "                                                                                                     \"it's...\n",
       "                                                                                                     'itself', ...]),\n",
       "                                                                         'sentence')])),\n",
       "                                       ('under',\n",
       "                                        RandomUnderSampler(random_state=42,\n",
       "                                                           sampling_strategy='majority')),\n",
       "                                       ('LR',\n",
       "                                        LogisticRegression(C=0.1,\n",
       "                                                           class_weight='balanced',\n",
       "                                                           random_state=42))]),\n",
       "             param_grid={'LR__C': [0.05, 0.01, 0.1, 1, 5],\n",
       "                         'LR__class_weight': [None, 'balanced', 0.25, 0.5,\n",
       "                                              0.75],\n",
       "                         'LR__solver': ['lbfgs', 'liblinear', 'sag', 'saga']},\n",
       "             return_train_score=True, scoring='recall')"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_final = GridSearchCV(under_log_eng_model,params,return_train_score=True,scoring='recall')\n",
    "lr_final.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.7192542129795626\n",
      "Precision Score: 0.15763830678960603\n",
      "Accuracy Score:0.5884576853353688\n",
      "F1 Score: 0.2585995745869411\n",
      "Confusion Matrix: \n",
      "[[43323 32158]\n",
      " [ 2349  6018]]\n"
     ]
    }
   ],
   "source": [
    "lr_final_ypreds = cross_val_predict(lr_final.best_estimator_, X_train,y_train)\n",
    "functions.metrics(y_train,lr_final_ypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.05, 'class_weight': None, 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleans up GS param dictionary to unpack it\n",
    "param_dict = {x.replace(\"LR__\", \"\"): v for x, v in lr_final.best_params_.items()}\n",
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.7365542557450803\n",
      "Mean Test Score: 0.7192530748746162\n"
     ]
    }
   ],
   "source": [
    "# Tell TFIDF which column to vectorize\n",
    "column_transformer = ColumnTransformer(\n",
    "    [('tfidf1', TfidfVectorizer(stop_words=sw.words('english')), 'sentence')], \n",
    "    remainder='passthrough')\n",
    "\n",
    "# fit the model\n",
    "final_log_eng_model = imbpipe(steps=[('tfidf1', column_transformer),\n",
    "                                     ('under',RandomUnderSampler('majority',random_state=42)),\n",
    "                                     ('LR',LogisticRegression(**param_dict))])\n",
    "# Evaluate results     \n",
    "final_log_eng_results = cross_validate(final_log_eng_model,X_train,y_train,return_train_score=True,scoring='recall')\n",
    "functions.mean_scores(final_log_eng_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.7192542129795626\n",
      "Precision Score: 0.15763830678960603\n",
      "Accuracy Score:0.5884576853353688\n",
      "F1 Score: 0.2585995745869411\n",
      "Confusion Matrix: \n",
      "[[43323 32158]\n",
      " [ 2349  6018]]\n"
     ]
    }
   ],
   "source": [
    "lr_final_ypreds = cross_val_predict(final_log_eng_model, X_train,y_train)\n",
    "functions.metrics(y_train,lr_final_ypreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model does end up giving us the best recall score and does a good job at catching the fake reviews while not predicting too many false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6000715563506261"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_log_eng_model.fit(X_train,y_train)\n",
    "final_log_eng_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig , ax = plt.subplots(figsize=(8,6))\n",
    "plot_confusion_matrix(final_log_eng_model,X_test,y_test,display_labels=['Real','Fake'],colorbar=False,ax=ax,values_format='d');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.6914244707570865\n",
      "Precision Score: 0.1573703552470396\n",
      "Accuracy Score:0.6000715563506261\n",
      "F1 Score: 0.25638637573177225\n",
      "Confusion Matrix: \n",
      "[[14845 10318]\n",
      " [  860  1927]]\n"
     ]
    }
   ],
   "source": [
    "functions.metrics(y_test,final_log_eng_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = final_log_eng_model.named_steps['LR']\n",
    "vals = sorted(classifier.coef_[0],reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/scraped_data/Broaddus_df','rb')\n",
    "df_Broaddus = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('data/scraped_data/BonTemps_df','rb')\n",
    "df_BonTemps = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('data/scraped_data/ruffinos_df','rb')\n",
    "df_ruffinos = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('data/scraped_data/social_df','rb')\n",
    "df_social = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_df = pd.concat([df_Broaddus,df_BonTemps,df_ruffinos,df_social],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/scraped_data/BonTemps_NR_review','rb')\n",
    "df_nr_bontemps = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('data/scraped_data/broaddus_NR_review','rb')\n",
    "df_nr_broaddus = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('data/scraped_data/ruffino_NR_reviews','rb')\n",
    "df_nr_ruffino = pickle.load(file)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_scraped = pd.concat([df_nr_bontemps, df_nr_broaddus,df_nr_ruffino])\n",
    "scraped_reviews_all = pd.concat([nr_scraped,scraped_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_test = functions.transform(scraped_reviews_all,'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = functions.test_df(scraped_test,'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf1',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('tfidf1',\n",
       "                                                  TfidfVectorizer(stop_words=['i',\n",
       "                                                                              'me',\n",
       "                                                                              'my',\n",
       "                                                                              'myself',\n",
       "                                                                              'we',\n",
       "                                                                              'our',\n",
       "                                                                              'ours',\n",
       "                                                                              'ourselves',\n",
       "                                                                              'you',\n",
       "                                                                              \"you're\",\n",
       "                                                                              \"you've\",\n",
       "                                                                              \"you'll\",\n",
       "                                                                              \"you'd\",\n",
       "                                                                              'your',\n",
       "                                                                              'yours',\n",
       "                                                                              'yourself',\n",
       "                                                                              'yourselves',\n",
       "                                                                              'he',\n",
       "                                                                              'him',\n",
       "                                                                              'his',\n",
       "                                                                              'himself',\n",
       "                                                                              'she',\n",
       "                                                                              \"she's\",\n",
       "                                                                              'her',\n",
       "                                                                              'hers',\n",
       "                                                                              'herself',\n",
       "                                                                              'it',\n",
       "                                                                              \"it's\",\n",
       "                                                                              'its',\n",
       "                                                                              'itself', ...]),\n",
       "                                                  'sentence')])),\n",
       "                ('under',\n",
       "                 RandomUnderSampler(random_state=42,\n",
       "                                    sampling_strategy='majority')),\n",
       "                ('LR', LogisticRegression(C=0.05, solver='liblinear'))])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_log_eng_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real_preds = final_log_eng_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_reviews_all['Label'] = pd.Series(y_real_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>gone</th>\n",
       "      <th>name</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Went based on reviews (4 1/2 stars) and I just...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This has to be one of the worst restaurants I ...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For starters some other guests who were dining...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One star was earned for the clean, casual surr...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im not a huge fan of this place. Their chicken...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>I was hoping for a lot more oomph in the food ...</td>\n",
       "      <td></td>\n",
       "      <td>Social Southern Table &amp; Bar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>I have been here twice and I must say the food...</td>\n",
       "      <td></td>\n",
       "      <td>Social Southern Table &amp; Bar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>Disclaimer: My choice in this place is not a r...</td>\n",
       "      <td></td>\n",
       "      <td>Social Southern Table &amp; Bar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Incredibly disappointing. My boyfriend and I w...</td>\n",
       "      <td></td>\n",
       "      <td>Social Southern Table &amp; Bar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Loved this place! Our daughter goes to UL so w...</td>\n",
       "      <td></td>\n",
       "      <td>Social Southern Table &amp; Bar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1819 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review gone  \\\n",
       "0     Went based on reviews (4 1/2 stars) and I just...        \n",
       "1     This has to be one of the worst restaurants I ...        \n",
       "2     For starters some other guests who were dining...        \n",
       "3     One star was earned for the clean, casual surr...        \n",
       "4     Im not a huge fan of this place. Their chicken...        \n",
       "...                                                 ...  ...   \n",
       "1814  I was hoping for a lot more oomph in the food ...        \n",
       "1815  I have been here twice and I must say the food...        \n",
       "1816  Disclaimer: My choice in this place is not a r...        \n",
       "1817  Incredibly disappointing. My boyfriend and I w...        \n",
       "1818  Loved this place! Our daughter goes to UL so w...        \n",
       "\n",
       "                             name  Label  \n",
       "0                             NaN      1  \n",
       "1                             NaN      1  \n",
       "2                             NaN      1  \n",
       "3                             NaN      0  \n",
       "4                             NaN      1  \n",
       "...                           ...    ...  \n",
       "1814  Social Southern Table & Bar      1  \n",
       "1815  Social Southern Table & Bar      1  \n",
       "1816  Social Southern Table & Bar      0  \n",
       "1817  Social Southern Table & Bar      0  \n",
       "1818  Social Southern Table & Bar      1  \n",
       "\n",
       "[1819 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_reviews_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
